# 技術課題

本節では，われわれが提案するSDN-MPIを概説し，本稿で取り扱う技術課題について記
す．そのために，まずSDN-MPIの構成技術であるSDN（Software-Defined Networking）
とMPI（Message Passing Interface）について説明する．

## SDN（Software-Defined Networking）

<!-- SDNの説明 -->
SDN（Software-Defined Networking）\cite{sdn}はパケットの流れを動的に集中制御可
能にするネットワークアーキテクチャである．従来のネットワークアーキテクチャでは
，パケット制御の決定を担うコントロールプレーンと実際のパケット転送を担うデータ
プレーンは，単一のネットワーク機器上に一体の機能となって実装されていた．SDNで
は，図\ref{fig:sdn-arch}に示すように，コントロールプレーンとデータプレーンを
それぞれ別々の機器に分離する．SDNスイッチと呼ばれるネットワーク機器はデータプ
レーンの処理，SDNコントローラはネットワークのコントロールプレーンの処理をソフ
トウェアにより担当する．この機能分離により，ネットワークの動的なプログラミング
制御が実現される．

![SDNのアーキテクチャ\label{fig:sdn-arch}](sdn-arch.pdf)

SDNでは，パケットの流れの制御を「フロー」という単位で行う．各SDNスイッチは，フ
ローの集合である「フローテーブル」を保持する．表\ref{tbl:flow-table}にスイッチ
が保持するフローテーブルの一例を示す．フローは，対象のパケットを限定するヘッダ
フィールドと，パケットに対して行う操作を定義するアクションから構成される．ヘッ
ダフィールドの例として，TCP/UDPポート番号，IPアドレス，MACアドレスがある．一方
，アクションには，パケットを特定のポートへ転送する，パケットのヘッダを書き換え
る，パケットをドロップするなどの操作を指定可能である．

\begin{table}[htb]
    \centering
    \caption{フローテーブルの一例}
    \medskip
    \label{tbl:flow-table}
    \begin{tabular}{lllll}
        \hline
        \multicolumn{3}{c}{ヘッダフィールド}        &          & アクション \\ \hline
        宛先MAC           & 送信元IP   & 宛先IP     & $\cdots$ &            \\ \hline
                          & 192.0.2.12 & 192.0.2.34 &          & ポート1    \\
                          & 192.0.2.34 & 192.0.2.56 &          & ポート2    \\
        ff:ff:ff:ff:ff:ff &            &            &          & ポート1,2  \\
        72:42:c1:e4:75:8c &            &            &          & ドロップ
    \end{tabular}
\end{table}

SDNスイッチはパケットを受信すると，マッチするフローをフローテーブルから検索し
，該当フローのアクションを実行する．SDNコントローラは，ネットワーク内の全ての
SDNスイッチのフローテーブルを操作することで，ネットワーク内のパケットの流れを
制御する．今日では，SDNの一実装として，OpenFlow\cite{McKeown2008}が業界標準規
格となりつつある．

## MPI（Message Passing Interface）

MPI（Message Passing Interface）
\cite{Gropp1999,MessagePassingInterfaceForum2015}は，メッセージパッシング方式
に基く，並列分散アプリケーションの開発に用いられるプロセス間通信ライブラリであ
る．メッセージパッシング方式では，並列分散プロセス同士は，メッセージと呼ばれる
データの交換により協調して動作する．MPIは，相互結合網を構成するハードウェアや
通信プロトコルの差異を吸収するため，アプリケーションの開発効率と可搬性が高い．
そのような理由から，HPCシステムで動作する並列分散アプリケーションの多くがMPIラ
イブラリを用いて実現されている．そのため，MPIの通信性能の改善は，アプリケー
ションの実行時間の短縮へとつながる．

MPIによるメッセージ通信は，1対1通信と集団通信に大別される．1対1通信関数は，2つ
のプロセス間の通信を取り扱う．`MPI_Send`や`MPI_Recv`はその代表例である．一方，
集団通信関数は複数のプロセスから構成されるグループ内の通信を取り扱う関数である
．あるプロセスから他の複数のプロセスに同一のデータを配信する`MPI_Bcast`や，複
数のプロセスから1つのプロセスにデータを縮約する`MPI_Reduce`は集団通信関数の一
例である．

これらのMPI通信関数は引数として，通信に参加するプロセスを指定する．1対1通信の
場合は送信元プロセス・宛先プロセスの識別子，集団通信の場合は通信に参加するプロ
セスのグループの識別子を，それぞれ引数として渡す．本稿では，以下，MPI関数の種
類，これらの参加プロセスの情報を合わせて，通信パターンと定義する．

## SDN-MPI実現のための技術課題

<!-- SDN-MPIのコンセプト -->
われわれは，\ref{sdnsoftware-defined-networking}節で述べたSDNによるフローの動
的制御機能に着眼し，並列分散プロセス間通信ライブラリMPIの通信性能向上を目的と
し，SDN-MPIの研究開発を推進してきた．図\ref{fig:sdn-mpi}に提案するSDN-MPIのコ
ンセプトを示す．SDN-MPIでは，MPIアプリケーションから通信パターンを抽出し，この
抽出された通信パターンから通信性能を向上するために最適なフロー制御を実現する．
このコンセプトに基づき，われわれはMPIの集合通信である`MPI_Bcast`，
`MPI_Allreduce`の通信パターンを抽出し，その通信性能を向上させる研究開発を推進
してきた．その結果，通信パターンに応じて，相互結合網内を流れるネットワークフ
ローを制御することにより，それぞれの集合通信の高速化が可能であることを示してき
た\cite{Dashdavaa2013,Takahashi2014}．

![SDN-MPI概念図\label{fig:sdn-mpi}](sdn-mpi.pdf)

しかし，複数のMPI関数を用いて実際のMPIアプリケーションの実行に合わせて発生する
通信パターンに応じて，相互結合網内を流れるパケットフローを制御する仕組みは未だ
実現できていない．実際のMPIアプリケーションでは，単一のアプリケーションが複数
のMPI関数を実行する．そのため，アプリケーションがMPI関数を呼び出すごとに，その
通信パターンをリアルタイムに把握する必要がある．そして，通信パターンに応じて，
通信性能を向上するように相互結合網内のフローの制御を行わなければいけない．本研
究では，MPIアプリケーションの実行に応じて，ネットワーク内のパケットフローを制
御可能にする仕組みを実現するに際して，以下を技術課題として設定する．

1. オーバーヘッドの削減：アプリケーションの実行とフローの制御は，可能な限り小さ
    いオーバーヘッドで同期しなければいけない．
2. スケーラビリティの向上：SDNスイッチにインストールできるフロー数の上限をでき
    るだけ増やすことができる方法が望ましい．
3. MPIに由来するパケットの識別：相互結合網内にはSSHなど，MPIと無関係なパケット
    も流れる．そのため，MPIが送出したパケットのみを判別し，制御する必要がある．

